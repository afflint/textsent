{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection\n",
    "Parameters for selecting features:\n",
    "- **raw**: take all tokens returned by the tokenizer\n",
    "- **pos**: keep ADJ and NOUNS only\n",
    "- **dep**: keep text depending on ADJ with negation\n",
    "\n",
    "Tokens:\n",
    "\n",
    "- **text**: take lower text\n",
    "- **lemma**: take lemma\n",
    "\n",
    "Weight:\n",
    "\n",
    "- **tfidf**: tfidf weighting\n",
    "- **sentiwn**: use average pos - neg scores in sentiwn\n",
    "- **combo**: tfidf * sentiwn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = pymongo.MongoClient()['textsent']\n",
    "yelp = db['yelp_simple']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def documents(collection, pos_filter=None, field='lower'):\n",
    "    pipeline = []\n",
    "    if pos_filter is not None:\n",
    "        m = {'$match': {'pos': {'$in': pos_filter}}}\n",
    "        pipeline.append(m)\n",
    "    p = {'$project': {'_id': 0, 'doc': 1, 'sentence': 1, 'position': 1, field: 1}}\n",
    "    s = {'$sort': {'doc': 1, 'sentence': 1, 'position': 1}}\n",
    "    g = {'$group': {'_id': {'doc': '$doc', 'sentence': '$sentence'}, 'tokens': {'$push': '${}'.format(field)}}}\n",
    "    k = {'$group': {'_id': '$_id.doc', 'tokens': {'$push': '$tokens'}}}\n",
    "    pipeline += [p, s, g, k]\n",
    "    return [(r['_id'], \". \".join([\" \".join(x) for x in r['tokens']]).replace('\\n', '')) for r in \n",
    "            collection.aggregate(pipeline, allowDiskUse=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = dict(documents(yelp, pos_filter=None, field='lower'))\n",
    "raw_lemma = dict(documents(yelp, pos_filter=None, field='lemma'))\n",
    "pos_text = dict(documents(yelp, pos_filter=['ADJ', 'NOUN'], field='lower'))\n",
    "pos_lemma = dict(documents(yelp, pos_filter=['ADJ', 'NOUN'], field='lemma'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'real good pizza nothing bad home. great crust wood. oven nice guy counter. good value money'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_lemma[12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = pd.read_csv('../data/yelp_example_1_small.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Not great not bad if you are in a hurry and need a bite then stop in if you are looking for a great pizza then keep looking.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D.loc[10].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dep(text, nlp, lemma=False):\n",
    "    s = nlp(text)\n",
    "    tokens = []\n",
    "    for token in s:\n",
    "        if token.dep_ == 'amod':\n",
    "            if lemma:\n",
    "                tokens += [token.lemma_, token.head.lemma_]\n",
    "            else:\n",
    "                tokens += [token.text.lower(), token.head.text.lower()]\n",
    "        elif token.dep_ == 'neg':\n",
    "            data = [x for x in token.head.children] + [token.head]\n",
    "            for x in data:\n",
    "                if lemma:\n",
    "                    w = x.lemma_\n",
    "                else:\n",
    "                    w = x.text.lower()\n",
    "                if x.pos_ == 'ADJ':\n",
    "                    tokens.append(\"NOT_{}\".format(w))\n",
    "                else:\n",
    "                    tokens.append(w)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_data = [(i, row.content) for i, row in D.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c01997363b534e0598c01a205d92626f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data = tqdm_notebook(dep_data)\n",
    "dep_text = [(i, \" \".join(dep(x, nlp, lemma=False))) for i, x in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d7a95cc24c442f28b476ab083963892",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data = tqdm_notebook(dep_data)\n",
    "dep_lemma = [(i, \" \".join(dep(x, nlp, lemma=True))) for i, x in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_text = dict(dep_text)\n",
    "dep_lemma = dict(dep_lemma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = {\n",
    "    'raw_text': raw_text,\n",
    "    'raw_lemma': raw_lemma,\n",
    "    'pos_text': pos_text,\n",
    "    'pos_lemma': pos_lemma,\n",
    "    'dep_text': dep_text,\n",
    "    'dep_lemma': dep_lemma\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/yelp_tset.json', 'w') as out:\n",
    "    json.dump(training, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/yelp_tset.json', 'r') as infile:\n",
    "    T = json.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Not great not bad if you are in a hurry and need a bite then stop in if you are looking for a great pizza then keep looking.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D.loc[10].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_text\n",
      "not great not bad if you are in a hurry and need a bite then stop in if you are looking for a great pizza then keep looking .\n",
      "raw_lemma\n",
      "not great not bad if -PRON- be in a hurry and need a bite then stop in if -PRON- be look for a great pizza then keep look .\n",
      "pos_text\n",
      "great bad hurry bite great pizza\n",
      "pos_lemma\n",
      "great bad hurry bite great pizza\n",
      "dep_text\n",
      "not NOT_great NOT_great not stop keep . NOT_bad great pizza\n",
      "dep_lemma\n",
      "not NOT_great NOT_great not stop keep . NOT_bad great pizza\n"
     ]
    }
   ],
   "source": [
    "for k, t in T.items():\n",
    "    print(k)\n",
    "    print(t['10'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
